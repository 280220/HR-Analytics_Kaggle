{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "systematic-healing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "#Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#Feature engineering, pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from feature_engine.encoding import OneHotEncoder, CountFrequencyEncoder, OrdinalEncoder, RareLabelEncoder, MeanEncoder\n",
    "from feature_engine import imputation as mdi\n",
    "from feature_engine.discretisation import EqualFrequencyDiscretiser\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "#xgboost\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "plain-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "test = pd.read_csv('data_test_clean.csv')\n",
    "#test=pd.read_csv('z_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "contrary-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data_train_clean.csv')\n",
    "#train = pd.read_csv('z_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "delayed-sentence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3832, 11), (9995, 12))"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape, train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "driven-census",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manage data on train set\n",
    "y_train = train['target']\n",
    "X_train = train.drop(['enrollee_id', 'target'], axis=1)\n",
    "\n",
    "# Manage data on test set\n",
    "X_test = test.drop('enrollee_id', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "collectible-telling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9995,), (9995, 10), (3832, 10))"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "spectacular-psychology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RareLabelEncoder with feature \"city\"\n",
    "\n",
    "rare_encoder = RareLabelEncoder(tol = 0, n_categories = 5, variables = 'city', max_n_categories = 5, replace_with = 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "defined-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=rare_encoder.fit_transform(X_train)\n",
    "X_test=rare_encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "equipped-timing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['city_103', 'Other', 'city_114', 'city_21', 'city_160', 'city_16'],\n",
       "       dtype=object),\n",
       " array(['city_160', 'Other', 'city_103', 'city_114', 'city_21', 'city_16'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.city.unique(), X_test.city.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "proud-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Null Imputation\n",
    "\n",
    "#imputer = IterativeImputer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "refined-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nulls = X_test.columns[X_test.isnull().any()].tolist()\n",
    "#nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "appointed-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in nulls:\n",
    "    #X_train[i] = imputer.fit_transform(X_train[[i]])\n",
    "    #X_train[i] = round(X_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "nonprofit-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OneHotEncoder with features 'relevent_experience', 'gender', 'city', 'enrolled_university', 'education_level', 'major_discipline'\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(variables=['relevent_experience', 'gender', 'city', 'enrolled_university', 'education_level', 'major_discipline'], drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "liked-biotechnology",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=one_hot_encoder.fit_transform(X_train)\n",
    "X_test=one_hot_encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "greenhouse-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#experience feature: Change to numeric\n",
    "\n",
    "X_train['experience']=np.where(X_train['experience'] =='>20', '20', X_train['experience'])\n",
    "X_train['experience']=np.where(X_train['experience'] =='<1', '0', X_train['experience'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "dying-tractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['experience']=np.where(X_test['experience'] =='>20', '20', X_test['experience'])\n",
    "X_test['experience']=np.where(X_test['experience'] =='<1', '0', X_test['experience'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "brazilian-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['experience']=pd.to_numeric(X_train['experience'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "juvenile-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['experience']=pd.to_numeric(X_test['experience'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "raising-tower",
   "metadata": {},
   "outputs": [],
   "source": [
    "#last new job feature: Change to numeric\n",
    "\n",
    "X_train['last_new_job']=np.where(X_train['last_new_job'] =='>4', '5', X_train['last_new_job'])\n",
    "X_train['last_new_job']=np.where(X_train['last_new_job'] =='never', '0', X_train['last_new_job'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "administrative-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['last_new_job']=np.where(X_test['last_new_job'] =='>4', '5', X_test['last_new_job'])\n",
    "X_test['last_new_job']=np.where(X_test['last_new_job'] =='never', '0', X_test['last_new_job'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "reliable-identifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['last_new_job']=pd.to_numeric(X_train['last_new_job'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "occupied-forwarding",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['last_new_job']=pd.to_numeric(X_test['last_new_job'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "administrative-elephant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city_development_index                         float64\n",
       "experience                                       int64\n",
       "last_new_job                                     int64\n",
       "training_hours                                   int64\n",
       "relevent_experience_Has relevent experience      int32\n",
       "relevent_experience_No relevent experience       int32\n",
       "gender_Male                                      int32\n",
       "gender_Female                                    int32\n",
       "gender_Other                                     int32\n",
       "city_city_103                                    int32\n",
       "city_Other                                       int32\n",
       "city_city_114                                    int32\n",
       "city_city_21                                     int32\n",
       "city_city_160                                    int32\n",
       "city_city_16                                     int32\n",
       "enrolled_university_no_enrollment                int32\n",
       "enrolled_university_Part time course             int32\n",
       "enrolled_university_Full time course             int32\n",
       "education_level_Graduate                         int32\n",
       "education_level_Masters                          int32\n",
       "education_level_Phd                              int32\n",
       "major_discipline_STEM                            int32\n",
       "major_discipline_Humanities                      int32\n",
       "major_discipline_Arts                            int32\n",
       "major_discipline_Business Degree                 int32\n",
       "major_discipline_Other                           int32\n",
       "major_discipline_No Major                        int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "silent-purple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city_development_index                         float64\n",
       "experience                                       int64\n",
       "last_new_job                                     int64\n",
       "training_hours                                   int64\n",
       "relevent_experience_Has relevent experience      int32\n",
       "relevent_experience_No relevent experience       int32\n",
       "gender_Male                                      int32\n",
       "gender_Female                                    int32\n",
       "gender_Other                                     int32\n",
       "city_city_103                                    int32\n",
       "city_Other                                       int32\n",
       "city_city_114                                    int32\n",
       "city_city_21                                     int32\n",
       "city_city_160                                    int32\n",
       "city_city_16                                     int32\n",
       "enrolled_university_no_enrollment                int32\n",
       "enrolled_university_Part time course             int32\n",
       "enrolled_university_Full time course             int32\n",
       "education_level_Graduate                         int32\n",
       "education_level_Masters                          int32\n",
       "education_level_Phd                              int32\n",
       "major_discipline_STEM                            int32\n",
       "major_discipline_Humanities                      int32\n",
       "major_discipline_Arts                            int32\n",
       "major_discipline_Business Degree                 int32\n",
       "major_discipline_Other                           int32\n",
       "major_discipline_No Major                        int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "emotional-queue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "completed-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV with XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(random_state=42)\n",
    "param_grid = {'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.001,0.05,0.1, 10], \n",
    "              'max_depth': [2,3,4,5,6],\n",
    "              'min_child_weight': [11],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [1000]}\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "attractive-vertex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  8.6min finished\n",
      "C:\\Users\\Anna\\Anaconda3\\envs\\ironhack\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:03:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs...\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'colsample_bytree': [0.7],\n",
       "                         'learning_rate': [0.001, 0.05, 0.1, 10],\n",
       "                         'max_depth': [2, 3, 4, 5, 6], 'min_child_weight': [11],\n",
       "                         'n_estimators': [1000],\n",
       "                         'objective': ['binary:logistic'], 'subsample': [0.8]},\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(estimator = xgb_model, cv=5, param_grid = param_grid , scoring = 'accuracy', verbose = 1, n_jobs = -1, refit=True)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "powered-works",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:0.7902951475737868\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Score:\" + str(grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "skilled-basement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 2, 'min_child_weight': 11, 'n_estimators': 1000, 'objective': 'binary:logistic', 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters: \" + str(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "composite-exception",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.7,\n",
       " 'learning_rate': 0.05,\n",
       " 'max_depth': 2,\n",
       " 'min_child_weight': 11,\n",
       " 'n_estimators': 1000,\n",
       " 'objective': 'binary:logistic',\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_parameters = grid.best_params_\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "complete-invention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:04:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anna\\Anaconda3\\envs\\ironhack\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_features_to_select=200 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "C:\\Users\\Anna\\Anaconda3\\envs\\ironhack\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:04:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFE(estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                            colsample_bylevel=1, colsample_bynode=1,\n",
       "                            colsample_bytree=0.7, gamma=0, gpu_id=-1,\n",
       "                            importance_type='gain', interaction_constraints='',\n",
       "                            learning_rate=0.05, max_delta_step=0, max_depth=2,\n",
       "                            min_child_weight=11, missing=nan,\n",
       "                            monotone_constraints='()', n_estimators=1000,\n",
       "                            n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "                            reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                            subsample=0.8, tree_method='exact',\n",
       "                            validate_parameters=1, verbosity=None),\n",
       "    n_features_to_select=200)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost model with RFE\n",
    "xgb_model = xgb.XGBClassifier(**best_parameters)\n",
    "xgb_model.fit(X_train,y_train)\n",
    "\n",
    "selector = RFE(xgb_model, 200, step=1)\n",
    "selector.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "normal-socket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#predict results\n",
    "y_predict = selector.predict(X_test)\n",
    "\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "involved-trace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3832"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "informed-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_train = selector.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "romance-danish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7042,  586],\n",
       "       [1428,  939]], dtype=int64)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_predict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "stunning-singapore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6599412278025791\n"
     ]
    }
   ],
   "source": [
    "auc=roc_auc_score(y_train, y_predict_train)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-scotland",
   "metadata": {},
   "source": [
    "Preparation of submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "grave-constraint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23603</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22499</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10465</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8293</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4246</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3827</th>\n",
       "      <td>8880</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3828</th>\n",
       "      <td>7886</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3829</th>\n",
       "      <td>12279</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3830</th>\n",
       "      <td>5326</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3831</th>\n",
       "      <td>4017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3832 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      enrollee_id  target\n",
       "0           23603     0.0\n",
       "1           22499     0.0\n",
       "2           10465     0.0\n",
       "3            8293     0.0\n",
       "4            4246     0.0\n",
       "...           ...     ...\n",
       "3827         8880     0.0\n",
       "3828         7886     0.0\n",
       "3829        12279     0.0\n",
       "3830         5326     0.0\n",
       "3831         4017     0.0\n",
       "\n",
       "[3832 rows x 2 columns]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission = pd.DataFrame({'enrollee_id': test.enrollee_id, 'target': y_predict})\n",
    "my_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "noted-stone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    3651\n",
       "1.0     181\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "brief-china",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3832"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submission.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "cutting-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you could use any filename. We choose submission here\n",
    "my_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final score: 53%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
